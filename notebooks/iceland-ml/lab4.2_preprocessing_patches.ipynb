{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6952056",
   "metadata": {},
   "source": [
    "## Section 1: Load and Inspect Sentinel-2 Data (8 min)\n",
    "\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6918632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"âœ… Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f34ef69",
   "metadata": {},
   "source": [
    "### Define Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa269f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "project_dir = Path(os.getenv('PROJECT_training2600')) / 'my_workspace'\n",
    "data_dir = project_dir / 'data' / 'sentinel2'\n",
    "output_dir = project_dir / 'data' / 'preprocessed'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "\n",
    "# List available scenes\n",
    "scene_files = sorted(data_dir.glob('sentinel2_*.tif'))\n",
    "print(f\"\\nâœ… Found {len(scene_files)} Sentinel-2 scenes:\")\n",
    "for f in scene_files:\n",
    "    print(f\"   - {f.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3892f246",
   "metadata": {},
   "source": [
    "### Load and Inspect a Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f043df55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load first scene\n",
    "scene_path = scene_files[0]\n",
    "\n",
    "with rasterio.open(scene_path) as src:\n",
    "    # Read metadata\n",
    "    print(\"ðŸ“Š Scene Metadata:\")\n",
    "    print(f\"   Dimensions: {src.width} x {src.height} pixels\")\n",
    "    print(f\"   Bands: {src.count}\")\n",
    "    print(f\"   CRS: {src.crs}\")\n",
    "    print(f\"   Resolution: {src.res} meters\")\n",
    "    print(f\"   Bounds: {src.bounds}\")\n",
    "    print(f\"   Data Type: {src.dtypes[0]}\")\n",
    "    \n",
    "    # Read all bands\n",
    "    data = src.read()  # Shape: (bands, height, width)\n",
    "    \n",
    "print(f\"\\nâœ… Loaded data shape: {data.shape}\")\n",
    "print(f\"   Data range: [{data.min()}, {data.max()}]\")\n",
    "print(f\"   Data type: {data.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f91bdb4",
   "metadata": {},
   "source": [
    "### Visualize RGB Composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1344ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming bands: B2, B3, B4, B8, B11, B12\n",
    "# RGB = B4, B3, B2 (Red, Green, Blue)\n",
    "band_names = ['B2', 'B3', 'B4', 'B8', 'B11', 'B12']\n",
    "rgb_indices = [2, 1, 0]  # B4=2, B3=1, B2=0 (0-indexed)\n",
    "\n",
    "# Extract RGB\n",
    "rgb = data[rgb_indices, :, :].transpose(1, 2, 0)  # (H, W, 3)\n",
    "\n",
    "# Normalize to 0-1 for display (clip at 2nd and 98th percentile)\n",
    "def normalize_for_display(img, percentile=2):\n",
    "    vmin, vmax = np.percentile(img, [percentile, 100-percentile])\n",
    "    img_norm = np.clip((img - vmin) / (vmax - vmin), 0, 1)\n",
    "    return img_norm\n",
    "\n",
    "rgb_display = normalize_for_display(rgb)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(rgb_display)\n",
    "plt.title(f\"RGB Composite: {scene_path.name}\", fontsize=14)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Statistics per band:\")\n",
    "for i, name in enumerate(band_names):\n",
    "    band_data = data[i]\n",
    "    print(f\"   {name}: mean={band_data.mean():.2f}, std={band_data.std():.2f}, range=[{band_data.min()}, {band_data.max()}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a96192",
   "metadata": {},
   "source": [
    "## Section 2: Patch Extraction (10 min)\n",
    "\n",
    "### Why Patches?\n",
    "Deep learning models work on fixed-size inputs. We divide large satellite images into smaller patches:\n",
    "- **Patch Size:** 224Ã—224 or 256Ã—256 pixels (common for vision models)\n",
    "- **Overlap:** Optional overlap between patches for better coverage\n",
    "- **Stride:** Controls spacing between patches\n",
    "\n",
    "### Extract Patches Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1e98ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches(image, patch_size=224, stride=224, min_valid_pixels=0.8):\n",
    "    \"\"\"\n",
    "    Extract patches from multi-band image.\n",
    "    \n",
    "    Args:\n",
    "        image: numpy array of shape (bands, height, width)\n",
    "        patch_size: size of square patch\n",
    "        stride: step size between patches\n",
    "        min_valid_pixels: minimum fraction of non-zero pixels\n",
    "    \n",
    "    Returns:\n",
    "        patches: list of numpy arrays (bands, patch_size, patch_size)\n",
    "        positions: list of (row, col) tuples\n",
    "    \"\"\"\n",
    "    bands, height, width = image.shape\n",
    "    patches = []\n",
    "    positions = []\n",
    "    \n",
    "    for i in range(0, height - patch_size + 1, stride):\n",
    "        for j in range(0, width - patch_size + 1, stride):\n",
    "            patch = image[:, i:i+patch_size, j:j+patch_size]\n",
    "            \n",
    "            # Check if patch has enough valid (non-zero) pixels\n",
    "            valid_ratio = (patch != 0).sum() / patch.size\n",
    "            \n",
    "            if valid_ratio >= min_valid_pixels:\n",
    "                patches.append(patch)\n",
    "                positions.append((i, j))\n",
    "    \n",
    "    return patches, positions\n",
    "\n",
    "print(\"âœ… Patch extraction function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0947e174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract patches from first scene\n",
    "patch_size = 224\n",
    "stride = 224  # No overlap (stride = patch_size)\n",
    "\n",
    "print(f\"ðŸ”ª Extracting {patch_size}x{patch_size} patches with stride {stride}...\")\n",
    "patches, positions = extract_patches(data, patch_size=patch_size, stride=stride)\n",
    "\n",
    "print(f\"\\nâœ… Extracted {len(patches)} valid patches\")\n",
    "print(f\"   Patch shape: {patches[0].shape}\")\n",
    "print(f\"   Total pixels per patch: {patches[0].size:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cd0d3c",
   "metadata": {},
   "source": [
    "### Visualize Sample Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d6bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first 6 patches\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx in range(min(6, len(patches))):\n",
    "    patch = patches[idx]\n",
    "    rgb_patch = patch[rgb_indices, :, :].transpose(1, 2, 0)\n",
    "    rgb_patch_display = normalize_for_display(rgb_patch)\n",
    "    \n",
    "    axes[idx].imshow(rgb_patch_display)\n",
    "    axes[idx].set_title(f\"Patch {idx+1} | Pos: {positions[idx]}\", fontsize=10)\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78166b3b",
   "metadata": {},
   "source": [
    "## Section 3: Normalization Techniques (8 min)\n",
    "\n",
    "### Why Normalize?\n",
    "Neural networks train better with normalized inputs:\n",
    "- **Faster convergence:** Reduces gradient magnitude variation\n",
    "- **Numerical stability:** Avoids overflow/underflow\n",
    "- **Better generalization:** Removes scaling bias\n",
    "\n",
    "### Common Normalization Methods\n",
    "1. **Min-Max Scaling:** Scale to [0, 1]\n",
    "2. **Standardization (Z-score):** Mean=0, Std=1\n",
    "3. **Percentile Clipping:** Robust to outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fc6fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_minmax(patches, data_min=None, data_max=None):\n",
    "    \"\"\"\n",
    "    Min-Max normalization to [0, 1].\n",
    "    \"\"\"\n",
    "    patches_arr = np.array(patches)  # (N, C, H, W)\n",
    "    \n",
    "    if data_min is None:\n",
    "        data_min = patches_arr.min(axis=(0, 2, 3), keepdims=True)  # Per-channel min\n",
    "    if data_max is None:\n",
    "        data_max = patches_arr.max(axis=(0, 2, 3), keepdims=True)  # Per-channel max\n",
    "    \n",
    "    normalized = (patches_arr - data_min) / (data_max - data_min + 1e-8)\n",
    "    return normalized, data_min, data_max\n",
    "\n",
    "\n",
    "def normalize_standardize(patches, mean=None, std=None):\n",
    "    \"\"\"\n",
    "    Standardization to mean=0, std=1.\n",
    "    \"\"\"\n",
    "    patches_arr = np.array(patches)  # (N, C, H, W)\n",
    "    \n",
    "    if mean is None:\n",
    "        mean = patches_arr.mean(axis=(0, 2, 3), keepdims=True)  # Per-channel mean\n",
    "    if std is None:\n",
    "        std = patches_arr.std(axis=(0, 2, 3), keepdims=True)  # Per-channel std\n",
    "    \n",
    "    normalized = (patches_arr - mean) / (std + 1e-8)\n",
    "    return normalized, mean, std\n",
    "\n",
    "\n",
    "def normalize_percentile(patches, lower=2, upper=98):\n",
    "    \"\"\"\n",
    "    Percentile-based normalization (robust to outliers).\n",
    "    \"\"\"\n",
    "    patches_arr = np.array(patches)\n",
    "    \n",
    "    # Compute percentiles per channel\n",
    "    p_lower = np.percentile(patches_arr, lower, axis=(0, 2, 3), keepdims=True)\n",
    "    p_upper = np.percentile(patches_arr, upper, axis=(0, 2, 3), keepdims=True)\n",
    "    \n",
    "    # Clip and normalize\n",
    "    patches_clipped = np.clip(patches_arr, p_lower, p_upper)\n",
    "    normalized = (patches_clipped - p_lower) / (p_upper - p_lower + 1e-8)\n",
    "    \n",
    "    return normalized, p_lower, p_upper\n",
    "\n",
    "print(\"âœ… Normalization functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd0a372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply standardization (common for pre-trained models)\n",
    "print(\"ðŸ”„ Applying standardization...\")\n",
    "patches_normalized, mean, std = normalize_standardize(patches)\n",
    "\n",
    "print(f\"\\nâœ… Normalization complete\")\n",
    "print(f\"   Original range: [{np.array(patches).min():.2f}, {np.array(patches).max():.2f}]\")\n",
    "print(f\"   Normalized range: [{patches_normalized.min():.2f}, {patches_normalized.max():.2f}]\")\n",
    "print(f\"   Normalized mean: {patches_normalized.mean():.6f}\")\n",
    "print(f\"   Normalized std: {patches_normalized.std():.6f}\")\n",
    "\n",
    "# Save normalization parameters\n",
    "norm_params = {\n",
    "    'method': 'standardization',\n",
    "    'mean': mean.squeeze().tolist(),\n",
    "    'std': std.squeeze().tolist(),\n",
    "    'band_names': band_names\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(output_dir / 'normalization_params.json', 'w') as f:\n",
    "    json.dump(norm_params, f, indent=2)\n",
    "\n",
    "print(f\"\\nðŸ’¾ Saved normalization parameters to: {output_dir / 'normalization_params.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa75079",
   "metadata": {},
   "source": [
    "## Section 4: Label Matching with CORINE Land Cover (7 min)\n",
    "\n",
    "### About CORINE Land Cover\n",
    "CORINE (Coordination of Information on the Environment) provides European land cover classification:\n",
    "- **Classes:** 44 land cover types\n",
    "- **Resolution:** 100m (resampled to match Sentinel-2)\n",
    "- **Updates:** Every 6 years\n",
    "\n",
    "### Simplified Classes for ML\n",
    "We'll use a subset of CORINE classes common in Iceland:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ef3bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified land cover classes for Iceland\n",
    "CLASS_MAPPING = {\n",
    "    'Urban': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],  # Artificial surfaces\n",
    "    'Agricultural': [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22],  # Agricultural areas\n",
    "    'Forest': [23, 24, 25],  # Forest\n",
    "    'Shrubland': [26, 27, 28, 29],  # Shrub and herbaceous\n",
    "    'Bare': [30, 31, 32, 33],  # Open spaces (lava, rock, glaciers)\n",
    "    'Wetland': [35, 36, 37, 38, 39],  # Wetlands\n",
    "    'Water': [40, 41, 42, 43, 44]  # Water bodies\n",
    "}\n",
    "\n",
    "# For this lab, we'll simulate labels (in real scenario, load CORINE raster)\n",
    "def generate_synthetic_labels(patches, class_names):\n",
    "    \"\"\"\n",
    "    Generate synthetic labels based on NDVI and brightness.\n",
    "    In real scenario, match with CORINE raster.\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    \n",
    "    for patch in patches:\n",
    "        # Calculate NDVI (simplified)\n",
    "        nir = patch[3].mean()  # B8\n",
    "        red = patch[2].mean()  # B4\n",
    "        ndvi = (nir - red) / (nir + red + 1e-8)\n",
    "        \n",
    "        # Heuristic classification\n",
    "        if ndvi > 0.4:\n",
    "            label = 'Forest'\n",
    "        elif ndvi > 0.2:\n",
    "            label = 'Shrubland'\n",
    "        elif patch.mean() < 500:\n",
    "            label = 'Water'\n",
    "        elif patch.mean() < 1000:\n",
    "            label = 'Wetland'\n",
    "        else:\n",
    "            label = 'Bare'\n",
    "        \n",
    "        labels.append(label)\n",
    "    \n",
    "    return labels\n",
    "\n",
    "# Generate labels\n",
    "class_names = list(CLASS_MAPPING.keys())\n",
    "labels = generate_synthetic_labels(patches, class_names)\n",
    "\n",
    "print(f\"âœ… Generated {len(labels)} labels\")\n",
    "print(f\"\\nðŸ“Š Label distribution:\")\n",
    "label_counts = pd.Series(labels).value_counts()\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214be5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to integers\n",
    "label_to_idx = {name: idx for idx, name in enumerate(class_names)}\n",
    "idx_to_label = {idx: name for name, idx in label_to_idx.items()}\n",
    "\n",
    "labels_int = [label_to_idx[label] for label in labels]\n",
    "\n",
    "print(f\"\\nâœ… Label mapping:\")\n",
    "for name, idx in label_to_idx.items():\n",
    "    count = labels.count(name)\n",
    "    print(f\"   {idx}: {name} ({count} patches)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9126dddf",
   "metadata": {},
   "source": [
    "## Section 5: Train/Val/Test Split (4 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c12acea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset: 70% train, 15% val, 15% test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = patches_normalized  # (N, C, H, W)\n",
    "y = np.array(labels_int)  # (N,)\n",
    "\n",
    "# First split: 70% train, 30% temp\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Second split: 50% val, 50% test (from temp)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"ðŸ“‚ Dataset Split:\")\n",
    "print(f\"   Train: {X_train.shape[0]} patches ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"   Val:   {X_val.shape[0]} patches ({X_val.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"   Test:  {X_test.shape[0]} patches ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"\\n   Total: {len(X)} patches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9197955",
   "metadata": {},
   "source": [
    "## Section 6: Save Preprocessed Dataset (3 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebdb71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as NumPy arrays (efficient for loading)\n",
    "print(\"ðŸ’¾ Saving preprocessed dataset...\\n\")\n",
    "\n",
    "np.save(output_dir / 'X_train.npy', X_train)\n",
    "np.save(output_dir / 'y_train.npy', y_train)\n",
    "np.save(output_dir / 'X_val.npy', X_val)\n",
    "np.save(output_dir / 'y_val.npy', y_val)\n",
    "np.save(output_dir / 'X_test.npy', X_test)\n",
    "np.save(output_dir / 'y_test.npy', y_test)\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    'patch_size': patch_size,\n",
    "    'stride': stride,\n",
    "    'num_bands': len(band_names),\n",
    "    'band_names': band_names,\n",
    "    'num_classes': len(class_names),\n",
    "    'class_names': class_names,\n",
    "    'label_mapping': label_to_idx,\n",
    "    'train_size': len(X_train),\n",
    "    'val_size': len(X_val),\n",
    "    'test_size': len(X_test),\n",
    "    'normalization': norm_params\n",
    "}\n",
    "\n",
    "with open(output_dir / 'dataset_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"âœ… Saved files to: {output_dir}\")\n",
    "print(f\"   - X_train.npy ({X_train.nbytes / 1e6:.2f} MB)\")\n",
    "print(f\"   - y_train.npy ({y_train.nbytes / 1e3:.2f} KB)\")\n",
    "print(f\"   - X_val.npy ({X_val.nbytes / 1e6:.2f} MB)\")\n",
    "print(f\"   - y_val.npy ({y_val.nbytes / 1e3:.2f} KB)\")\n",
    "print(f\"   - X_test.npy ({X_test.nbytes / 1e6:.2f} MB)\")\n",
    "print(f\"   - y_test.npy ({y_test.nbytes / 1e3:.2f} KB)\")\n",
    "print(f\"   - dataset_metadata.json\")\n",
    "print(f\"   - normalization_params.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5329a7",
   "metadata": {},
   "source": [
    "### Verify Saved Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139add23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and verify\n",
    "X_train_loaded = np.load(output_dir / 'X_train.npy')\n",
    "y_train_loaded = np.load(output_dir / 'y_train.npy')\n",
    "\n",
    "print(\"ðŸ” Verification:\")\n",
    "print(f\"   Loaded X_train shape: {X_train_loaded.shape}\")\n",
    "print(f\"   Loaded y_train shape: {y_train_loaded.shape}\")\n",
    "print(f\"   Data matches: {np.array_equal(X_train, X_train_loaded)}\")\n",
    "print(f\"   Labels match: {np.array_equal(y_train, y_train_loaded)}\")\n",
    "print(\"\\nâœ… All data saved and verified successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328548c2",
   "metadata": {},
   "source": [
    "## Summary & Next Steps\n",
    "\n",
    "### What We Covered\n",
    "âœ… Loaded Sentinel-2 GeoTIFF imagery  \n",
    "âœ… Extracted 224Ã—224 patches from scenes  \n",
    "âœ… Applied standardization normalization  \n",
    "âœ… Generated/matched land cover labels  \n",
    "âœ… Created train/val/test split (70/15/15)  \n",
    "âœ… Saved ML-ready dataset  \n",
    "\n",
    "### Dataset Statistics\n",
    "- **Total Patches:** Variable (depends on scene size)\n",
    "- **Patch Size:** 224Ã—224 pixels\n",
    "- **Bands:** 6 (B2, B3, B4, B8, B11, B12)\n",
    "- **Classes:** 7 land cover types\n",
    "- **Normalization:** Standardization (mean=0, std=1)\n",
    "- **Format:** NumPy arrays (.npy)\n",
    "\n",
    "### Key Preprocessing Concepts\n",
    "- **Patch Extraction:** Divide large images into fixed-size inputs\n",
    "- **Normalization:** Scale inputs for neural network training\n",
    "- **Label Matching:** Align satellite pixels with ground truth\n",
    "- **Data Splitting:** Separate train/val/test to avoid overfitting\n",
    "\n",
    "### Prepare for Lab 5.1\n",
    "Next lab: **Baseline Model Training**\n",
    "- We'll train a CNN classifier\n",
    "- Use PyTorch/TensorFlow\n",
    "- Submit training job to GPU partition\n",
    "- Track training metrics\n",
    "\n",
    "### Best Practices\n",
    "1. **Always save normalization parameters** (needed for inference)\n",
    "2. **Check for class imbalance** (use weighted loss if needed)\n",
    "3. **Validate patches visually** (ensure no artifacts)\n",
    "4. **Document metadata** (bands, resolution, classes)\n",
    "\n",
    "### Additional Resources\n",
    "- **Rasterio Docs:** https://rasterio.readthedocs.io\n",
    "- **Data Normalization:** https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "- **CORINE Land Cover:** https://land.copernicus.eu/pan-european/corine-land-cover\n",
    "\n",
    "### Homework (Optional)\n",
    "1. Experiment with different patch sizes (128, 256, 512)\n",
    "2. Try overlapping patches (stride < patch_size)\n",
    "3. Compare normalization methods (min-max vs standardization)\n",
    "4. Visualize class distribution per split\n",
    "\n",
    "---\n",
    "\n",
    "**Fantastic work!** Your data is now ready for machine learning! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
